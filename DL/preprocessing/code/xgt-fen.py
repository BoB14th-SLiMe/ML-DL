#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
preprocess_xgt_fen_embed.py
Aë²„ì „: xgt_fen ì „ìš© embedding/feature ì „ì²˜ë¦¬ + ê°„ë‹¨ ì •ê·œí™”

ë‘ ëª¨ë“œ ì œê³µ:
  --fit        : xgt_var_vocab + ì •ê·œí™” íŒŒë¼ë¯¸í„° ìƒì„± í›„ xgt_fen.npy ì €ì¥
  --transform  : ê¸°ì¡´ xgt_var_vocab + ì •ê·œí™” íŒŒë¼ë¯¸í„° ì‚¬ìš©

ì…ë ¥ JSONLì—ì„œ ì‚¬ìš©í•˜ëŠ” í•„ë“œ:
  - protocol == "xgt_fen"
  - xgt_fen.vars      : list[str] ë˜ëŠ” "R17,R20" ê°™ì€ str
  - xgt_fen.source    : int ë˜ëŠ” "0x11" ê°™ì€ hex ë¬¸ìì—´
  - xgt_fen.fenetpos  : int ë˜ëŠ” "0x01" ê°™ì€ hex ë¬¸ìì—´ (ìƒìœ„ 4bit = base, í•˜ìœ„ 4bit = slot)
  - xgt_fen.cmd       : int ë˜ëŠ” "0x0054" ê°™ì€ hex ë¬¸ìì—´
  - xgt_fen.dtype     : int ë˜ëŠ” "0x0014" (ë˜ëŠ” xgt_fen.dype)
  - xgt_fen.blkcnt    : int
  - xgt_fen.datasize  : int
  - xgt_fen.errstat   : int ë˜ëŠ” "0x0000" ê°™ì€ hex ë¬¸ìì—´
  - xgt_fen.data      : list[str] ë˜ëŠ” str (hex string)

ì¶œë ¥:
  - xgt_fen.npy (structured numpy ë°°ì—´)
  - xgt_var_vocab.json (ë³€ìˆ˜ ì´ë¦„ â†’ ID)
  - xgt_fen_norm_params.json (ì •ê·œí™”ìš© min/max)

xgt_fen.npy dtype (ê° í•„ë“œëŠ” ì´ë¯¸ ì•„ë˜ ê·œì¹™ëŒ€ë¡œ ìŠ¤ì¼€ì¼ë§ë¨):
  - xgt_var_id         (int32)   â† vars[0] â†’ ID, Embeddingìš© (ì •ê·œí™” X)
  - xgt_var_cnt        (float32) â† Min-Max ì •ê·œí™”
  - xgt_source         (float32) â† Min-Max ì •ê·œí™”
  - xgt_fenet_base     (float32) â† Min-Max ì •ê·œí™”
  - xgt_fenet_slot     (float32) â† Min-Max ì •ê·œí™”
  - xgt_cmd            (float32) â† Min-Max ì •ê·œí™”
  - xgt_dtype          (float32) â† Min-Max ì •ê·œí™”
  - xgt_blkcnt         (float32) â† Min-Max ì •ê·œí™”
  - xgt_err_flag       (float32) (0.0 / 1.0, ì •ê·œí™” X)
  - xgt_err_code       (float32) â† Min-Max ì •ê·œí™”
  - xgt_datasize       (float32) â† Min-Max ì •ê·œí™”
  - xgt_data_missing   (float32) (0.0 / 1.0, datasize>0 & data ì—†ìŒì´ë©´ 1.0)
  - xgt_data_len_chars (float32) â† Min-Max ì •ê·œí™”
  - xgt_data_num_spaces(float32) â† Min-Max ì •ê·œí™”
  - xgt_data_is_hex    (float32) (0.0 / 1.0, ì •ê·œí™” X)
  - xgt_data_n_bytes   (float32) â† Min-Max ì •ê·œí™”
  - xgt_data_zero_ratio(float32) (0.0 ~ 1.0, ì •ê·œí™” X)
  - xgt_data_first_byte(float32) (0~1, ì›ë˜ 0~255ë¥¼ /255.0)
  - xgt_data_last_byte (float32) (0~1, ì›ë˜ 0~255ë¥¼ /255.0)
  - xgt_data_mean_byte (float32) (0~1, ì›ë˜ 0~255ë¥¼ /255.0)
  - xgt_data_bucket    (float32) (hash bucket, ì •ê·œí™” X)

ì‹¤ì‹œê°„ / ë‹¨ì¼ íŒ¨í‚· ì²˜ë¦¬:
  - xgt_var_vocab.json, xgt_fen_norm_params.json ë¡œë“œ í›„
    preprocess_xgt_fen_with_norm(obj, var_map, norm_params) í˜¸ì¶œ
"""

import json
import argparse
import numpy as np
from pathlib import Path
from typing import Any, Dict, List
import re

# ---------------------------------------------
# Feature ì´ë¦„ (ì„¤ëª…ìš©, ì½”ë“œ ë‚´ë¶€ì—ì„œëŠ” dtypeì´ source of truth)
# ---------------------------------------------
FEATURE_NAMES = [
    "xgt_var_id",
    "xgt_var_cnt",
    "xgt_source",
    "xgt_fenet_base",
    "xgt_fenet_slot",
    "xgt_cmd",
    "xgt_dtype",
    "xgt_blkcnt",
    "xgt_err_flag",
    "xgt_err_code",
    "xgt_datasize",
    # ğŸ‘‡ ìƒˆë¡œ ì¶”ê°€ë˜ëŠ” 8ê°œ
    "xgt_addr_count",
    "xgt_addr_min",
    "xgt_addr_max",
    "xgt_addr_range",
    "xgt_word_min",
    "xgt_word_max",
    "xgt_word_mean",
    "xgt_word_std",
    # ê¸°ì¡´
    "xgt_data_missing",
    "xgt_data_len_chars",
    "xgt_data_num_spaces",
    "xgt_data_is_hex",
    "xgt_data_n_bytes",
    "xgt_data_zero_ratio",
    "xgt_data_first_byte",
    "xgt_data_last_byte",
    "xgt_data_mean_byte",
    "xgt_data_bucket",
]

NORM_FIELDS = [
    "xgt_var_cnt",
    "xgt_source",
    "xgt_fenet_base",
    "xgt_fenet_slot",
    "xgt_cmd",
    "xgt_dtype",
    "xgt_blkcnt",
    "xgt_err_code",
    "xgt_datasize",
    "xgt_data_len_chars",
    "xgt_data_num_spaces",
    "xgt_data_n_bytes",
    # ğŸ‘‡ translated_addr / word_value í†µê³„ë„ ì •ê·œí™” ëŒ€ìƒ ì¶”ê°€
    "xgt_addr_count",
    "xgt_addr_min",
    "xgt_addr_max",
    "xgt_addr_range",
    "xgt_word_min",
    "xgt_word_max",
    "xgt_word_mean",
    "xgt_word_std",
]


NORM_PARAMS_FILE = "xgt_fen_norm_params.json"


# ---------------------------------------------
# Var ID ìƒì„±ê¸° (vars[0] â†’ ID)
# ---------------------------------------------
def get_var_id_factory(var_map: Dict[str, int]):
    """
    var_map: {"R17": 1, "R20": 2, ...}
    """
    next_id = max(var_map.values()) + 1 if var_map else 1

    def get_var_id(var_name: str) -> int:
        nonlocal next_id
        if not var_name:
            return 0  # UNK
        if var_name not in var_map:
            var_map[var_name] = next_id
            next_id += 1
        return var_map[var_name]

    return get_var_id


# ---------------------------------------------
# ì•ˆì „í•œ int ë³€í™˜ (10ì§„ìˆ˜ + 16ì§„ìˆ˜ "0x.." ëª¨ë‘ ì§€ì›)
# ---------------------------------------------
def to_int(value: Any, default: int = 0) -> int:
    """
    "10", 10, "0x10" ê°™ì€ ê°’ë“¤ì„ ëª¨ë‘ intë¡œ ë³€í™˜.
    - "0x.." í˜•íƒœë©´ 16ì§„ìˆ˜ë¡œ ì¸ì‹
    - ê·¸ ì™¸ëŠ” 10ì§„ìˆ˜ ì‹œë„
    """
    if value is None:
        return default

    s = str(value).strip()
    if not s:
        return default

    try:
        # "0x10" ê°™ì´ base ìë™ ì¸ì‹
        return int(s, 0)
    except ValueError:
        try:
            return int(s)
        except ValueError:
            return default

# ---------------------------------------------
# translated_addr / word_value ë¦¬ìŠ¤íŠ¸ íŒŒì‹± + í†µê³„
# ---------------------------------------------
# ---------------------------------------------
# translated_addr / word_value ë¦¬ìŠ¤íŠ¸ íŒŒì‹± + í†µê³„
# ---------------------------------------------
def parse_xgt_translated_addr_list(value: Any) -> List[int]:
    """
    xgt_fen.translated_addr: ["M1","M2", ...] ê°™ì€ ê°’ë“¤ì„ ìˆ«ì ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜.
    - "M1" -> 1, "M2" -> 2 ì²˜ëŸ¼ 'ìˆ«ì ë¶€ë¶„'ë§Œ ì¶”ì¶œí•´ì„œ ì‚¬ìš©
    """
    result: List[int] = []

    def _handle_one(x: Any):
        s = str(x).strip()
        if not s:
            return
        # ë¬¸ìì—´ ì•ˆì—ì„œ ìˆ«ì ë¶€ë¶„ë§Œ ì¶”ì¶œ
        m = re.search(r"(\d+)", s)
        if m:
            try:
                result.append(int(m.group(1)))
            except ValueError:
                pass

    if value is None:
        return result

    if isinstance(value, list):
        for v in value:
            _handle_one(v)
        return result

    s = str(value).strip()
    # JSON ë¬¸ìì—´ í˜•íƒœì¸ ê²½ìš° ì˜ˆ: '["M1","M2"]'
    if s.startswith("[") and s.endswith("]"):
        try:
            arr = json.loads(s)
            return parse_xgt_translated_addr_list(arr)
        except Exception:
            _handle_one(s)
            return result

    _handle_one(s)
    return result


def parse_xgt_word_value_list(value: Any) -> List[float]:
    """
    xgt_fen.word_value: ["0","1","2"] or [0,1,2] or "0" ë“±ì„ float ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜.
    """
    result: List[float] = []

    def _handle_one(x: Any):
        try:
            v = float(to_int(x))
            result.append(v)
        except Exception:
            pass

    if value is None:
        return result

    if isinstance(value, list):
        for v in value:
            _handle_one(v)
        return result

    s = str(value).strip()
    if s.startswith("[") and s.endswith("]"):
        try:
            arr = json.loads(s)
            return parse_xgt_word_value_list(arr)
        except Exception:
            _handle_one(s)
            return result

    _handle_one(s)
    return result


def compute_xgt_addr_stats(addrs: List[int]) -> Dict[str, float]:
    """
    translated_addr(ìˆ«ìí™”ëœ ê²ƒ) ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ count/min/max/range ê³„ì‚°.
    """
    if not addrs:
        return {
            "count": 0.0,
            "min": 0.0,
            "max": 0.0,
            "range": 0.0,
        }
    count = float(len(addrs))
    amin = float(min(addrs))
    amax = float(max(addrs))
    arange = float(amax - amin)
    return {
        "count": count,
        "min": amin,
        "max": amax,
        "range": arange,
    }


def compute_xgt_word_stats(vals: List[float]) -> Dict[str, float]:
    """
    word_value ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ min/max/mean/std ê³„ì‚°.
    """
    if not vals:
        return {
            "min": 0.0,
            "max": 0.0,
            "mean": 0.0,
            "std": 0.0,
        }
    vmin = float(min(vals))
    vmax = float(max(vals))
    mean = float(sum(vals) / len(vals))
    var = float(sum((v - mean) ** 2 for v in vals) / len(vals))
    std = float(var ** 0.5)
    return {
        "min": vmin,
        "max": vmax,
        "mean": mean,
        "std": std,
    }


# ---------------------------------------------
# xgt_fen.data ìš”ì•½ í”¼ì²˜
# ---------------------------------------------
def extract_xgt_data_features(data: Any) -> Dict[str, float]:
    """
    xgt_fen.data (string ë˜ëŠ” string ë¦¬ìŠ¤íŠ¸) -> ì—¬ëŸ¬ ê°œ numeric featureë¡œ ë³€í™˜

    ì˜ˆì‹œ:
        "xgt_fen.data": [
            "0000",
            "000000000000000000000000",
            "05001e00f50000001c002700",
            "3e01"
        ]

    ê° ì›ì†ŒëŠ” hex string ì´ë¼ê³  ê°€ì •í•˜ê³ ,
    ê³µë°± ì œê±° í›„ 2ê¸€ìì”© ì˜ë¼ì„œ ë°”ì´íŠ¸ ë°°ì—´ì„ ë§Œë“ ë‹¤.
    """

    # 1) dataë¥¼ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¡œ í†µì¼
    if data is None:
        strings: List[str] = []
    elif isinstance(data, list):
        strings = [str(x).strip() for x in data if str(x).strip()]
    else:
        s = str(data).strip()
        strings = [s] if s else []

    # ì „ì²´ ë¬¸ìì—´ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸° (ê³µë°±ìœ¼ë¡œ join)
    joined = " ".join(strings)
    s = joined
    s_no_space = s.replace(" ", "")

    # ê³µí†µ ë¬¸ìì—´ í”¼ì²˜
    length_chars = len(s)
    num_spaces = s.count(" ")

    # hex ì—¬ë¶€ íŒë‹¨
    hex_chars = sum(ch in "0123456789abcdefABCDEF" for ch in s_no_space)
    non_hex_chars = len(s_no_space) - hex_chars
    is_hex = int(len(s_no_space) > 0 and non_hex_chars == 0)

    # 2) hexë¡œ í•´ì„í•´ì„œ ë°”ì´íŠ¸ ë‚˜ì—´ ë§Œë“¤ê¸°
    bytes_values: List[int] = []
    if is_hex:
        for elem in strings:
            hex_str = elem.replace(" ", "")
            if len(hex_str) < 2:
                continue
            # 2ê¸€ìì”© ì˜ë¼ì„œ ë°”ì´íŠ¸ë¡œ
            for i in range(0, len(hex_str) - 1, 2):
                chunk = hex_str[i:i+2]
                try:
                    v = int(chunk, 16)
                    bytes_values.append(v)
                except ValueError:
                    continue

    n_bytes = len(bytes_values)
    if n_bytes > 0:
        zero_count = sum(1 for v in bytes_values if v == 0)
        zero_ratio = zero_count / float(n_bytes)
        first_byte = bytes_values[0]
        last_byte = bytes_values[-1]
        mean_byte = float(sum(bytes_values) / float(n_bytes))
    else:
        zero_ratio = 0.0
        first_byte = 0
        last_byte = 0
        mean_byte = 0.0

    # ë™ì¼ ë¬¸ìì—´ íŒ¨í„´ìš© í•´ì‹œ ë²„í‚· (embeddingìœ¼ë¡œ ì“°ê³  ì‹¶ìœ¼ë©´ ì´ ê°’ ì‚¬ìš©)
    bucket = hash(s) % 1024 if s else 0

    return {
        "xgt_data_len_chars": float(length_chars),
        "xgt_data_num_spaces": float(num_spaces),
        "xgt_data_is_hex": float(is_hex),
        "xgt_data_n_bytes": float(n_bytes),
        "xgt_data_zero_ratio": float(zero_ratio),
        "xgt_data_first_byte": float(first_byte),
        "xgt_data_last_byte": float(last_byte),
        "xgt_data_mean_byte": float(mean_byte),
        "xgt_data_bucket": float(bucket),
    }


# ---------------------------------------------
# í•œ ë ˆì½”ë“œ(xgt_fen) ì „ì²˜ë¦¬ (ì •ê·œí™” ì „ RAW feature)
# ---------------------------------------------
def preprocess_xgt_record(obj: Dict[str, Any], get_var_id) -> Dict[str, float]:
    """
    protocol == "xgt_fen" ì¸ ë ˆì½”ë“œë¥¼ RAW feature dictë¡œ ë³€í™˜
    (ì •ê·œí™”ëŠ” ë‚˜ì¤‘ ë‹¨ê³„ì—ì„œ ìˆ˜í–‰)
    """

    feat: Dict[str, float] = {}

    # 1) vars â†’ var_id / var_cnt
    vars_field = obj.get("xgt_fen.vars")

    var_names: List[str] = []
    if isinstance(vars_field, list):
        var_names = [str(v).strip() for v in vars_field if str(v).strip()]
    elif isinstance(vars_field, str):
        # "R17,R20" ê°™ì€ ê²½ìš°
        for part in vars_field.split(","):
            p = part.strip()
            if p:
                var_names.append(p)

    if var_names:
        first_var = var_names[0]
        var_cnt = len(var_names)
    else:
        first_var = ""
        var_cnt = 0

    var_id = get_var_id(first_var) if first_var else 0
    feat["xgt_var_id"] = int(var_id)      # ì €ì¥ë„ int, dtypeë„ int32
    feat["xgt_var_cnt"] = float(var_cnt)

    # 2) í—¤ë”/ëª…ë ¹ í•„ë“œ + errstat ì²˜ë¦¬
    source = to_int(obj.get("xgt_fen.source"))
    fenetpos = to_int(obj.get("xgt_fen.fenetpos"))
    cmd = to_int(obj.get("xgt_fen.cmd"))
    dtype = to_int(obj.get("xgt_fen.dtype") or obj.get("xgt_fen.dype"))
    blkcnt = to_int(obj.get("xgt_fen.blkcnt"))
    datasize = to_int(obj.get("xgt_fen.datasize"))

    # errstat â†’ ì—ëŸ¬ ì½”ë“œ / í”Œë˜ê·¸
    errstat_raw = obj.get("xgt_fen.errstat")
    err_code = to_int(errstat_raw)
    err_flag = 1.0 if err_code != 0 else 0.0

    base = (fenetpos >> 4) & 0x0F
    slot = fenetpos & 0x0F

    feat["xgt_source"] = float(source)
    feat["xgt_fenet_base"] = float(base)
    feat["xgt_fenet_slot"] = float(slot)
    feat["xgt_cmd"] = float(cmd)
    feat["xgt_dtype"] = float(dtype)
    feat["xgt_blkcnt"] = float(blkcnt)
    feat["xgt_datasize"] = float(datasize)

    feat["xgt_err_code"] = float(err_code)
    feat["xgt_err_flag"] = float(err_flag)

    # 3) data ìš”ì•½
    data_field = obj.get("xgt_fen.data")
    data_feats = extract_xgt_data_features(data_field)
    feat.update(data_feats)

    # 4) ë°ì´í„° ì—†ìŒ í”Œë˜ê·¸ ì¶”ê°€
    length_chars = data_feats.get("xgt_data_len_chars", 0.0)
    xgt_data_missing = 1.0 if (datasize > 0 and length_chars == 0.0) else 0.0
    feat["xgt_data_missing"] = float(xgt_data_missing)

    # 5) translated_addr / word_value í†µê³„ í”¼ì²˜ ì¶”ê°€ (M1, M2, ... ì²˜ë¦¬)
    translated_addr_raw = obj.get("xgt_fen.translated_addr")
    word_value_raw      = obj.get("xgt_fen.word_value")

    addr_list = parse_xgt_translated_addr_list(translated_addr_raw)
    word_list = parse_xgt_word_value_list(word_value_raw)

    addr_stats = compute_xgt_addr_stats(addr_list)
    word_stats = compute_xgt_word_stats(word_list)

    feat["xgt_addr_count"] = addr_stats["count"]
    feat["xgt_addr_min"]   = addr_stats["min"]
    feat["xgt_addr_max"]   = addr_stats["max"]
    feat["xgt_addr_range"] = addr_stats["range"]

    feat["xgt_word_min"]   = word_stats["min"]
    feat["xgt_word_max"]   = word_stats["max"]
    feat["xgt_word_mean"]  = word_stats["mean"]
    feat["xgt_word_std"]   = word_stats["std"]

    return feat


# ---------------------------------------------
# Min-Max ì •ê·œí™” í•¨ìˆ˜
# ---------------------------------------------
def minmax_norm(val: float, vmin: float, vmax: float) -> float:
    if vmax <= vmin:
        return 0.0
    return (val - vmin) / (vmax - vmin + 1e-9)


# ---------------------------------------------
# RAW feature â†’ ì •ê·œí™” featureë¡œ ë³€í™˜ (ê³µí†µ ë¡œì§)
# ---------------------------------------------
def apply_norm_to_xgt_feat(raw_feat: Dict[str, float],
                           norm_params: Dict[str, Dict[str, float]]) -> Dict[str, float]:
    feat: Dict[str, float] = {}
    feat["xgt_var_id"] = int(raw_feat.get("xgt_var_id", 0))

    for f in NORM_FIELDS:
        raw_v = float(raw_feat.get(f, 0.0))
        p = norm_params.get(f, {})
        vmin = float(p.get("min", 0.0))
        vmax = float(p.get("max", 1.0))

        if f == "xgt_cmd":
            # âœ… sentinel ë¡œì§ ì¶”ê°€
            if raw_v < vmin or raw_v > vmax:
                feat[f] = -2.0
            elif vmax > vmin:
                feat[f] = (raw_v - vmin) / (vmax - vmin + 1e-9)
            else:
                feat[f] = 0.0
        else:
            feat[f] = float(minmax_norm(raw_v, vmin, vmax))

    # ë‚˜ë¨¸ì§€ëŠ” ê·¸ëŒ€ë¡œ
    feat["xgt_err_flag"]       = float(raw_feat.get("xgt_err_flag", 0.0))
    feat["xgt_data_missing"]   = float(raw_feat.get("xgt_data_missing", 0.0))
    feat["xgt_data_is_hex"]    = float(raw_feat.get("xgt_data_is_hex", 0.0))
    feat["xgt_data_zero_ratio"]= float(raw_feat.get("xgt_data_zero_ratio", 0.0))
    feat["xgt_data_bucket"]    = float(raw_feat.get("xgt_data_bucket", 0.0))

    fb = float(raw_feat.get("xgt_data_first_byte", 0.0))
    lb = float(raw_feat.get("xgt_data_last_byte", 0.0))
    mb = float(raw_feat.get("xgt_data_mean_byte", 0.0))
    feat["xgt_data_first_byte"] = fb / 255.0
    feat["xgt_data_last_byte"]  = lb / 255.0
    feat["xgt_data_mean_byte"]  = mb / 255.0

    return feat


# ---------------------------------------------
# ë‹¨ì¼ íŒ¨í‚· + ì •ê·œí™”ê¹Œì§€ ì²˜ë¦¬ (ì‹¤ì‹œê°„/ìš´ì˜ ìš©)
# ---------------------------------------------
def preprocess_xgt_fen_with_norm(
    obj: Dict[str, Any],
    var_map: Dict[str, int],
    norm_params: Dict[str, Dict[str, float]],
) -> Dict[str, float]:
    """
    ë‹¨ì¼ xgt_fen íŒ¨í‚· objì— ëŒ€í•´
    - xgt_var_id (int)
    - ë‚˜ë¨¸ì§€ numeric feature (ì •ê·œí™” í¬í•¨)
    ë¥¼ ëª¨ë‘ ë‹´ì€ dict ë°˜í™˜.

    ì‚¬ìš© ì˜ˆ:
        var_map = json.loads(open("xgt_var_vocab.json","r",encoding="utf-8").read())
        norm_params = json.loads(open("xgt_fen_norm_params.json","r",encoding="utf-8").read())

        feat = preprocess_xgt_fen_with_norm(obj, var_map, norm_params)
    """
    get_var_id = get_var_id_factory(var_map)
    raw_feat = preprocess_xgt_record(obj, get_var_id)
    norm_feat = apply_norm_to_xgt_feat(raw_feat, norm_params)
    return norm_feat


# ---------------------------------------------
# FIT
# ---------------------------------------------
def fit_preprocess(input_path: Path, out_dir: Path):

    out_dir.mkdir(parents=True, exist_ok=True)

    var_map: Dict[str, int] = {}
    get_var_id = get_var_id_factory(var_map)

    rows_raw: List[Dict[str, float]] = []

    with input_path.open("r", encoding="utf-8") as fin:
        for line in fin:
            line = line.strip()
            if not line:
                continue
            try:
                obj = json.loads(line)
            except Exception:
                continue

            if obj.get("protocol") != "xgt_fen":
                continue

            feat = preprocess_xgt_record(obj, get_var_id)
            rows_raw.append(feat)

    # vocab ì €ì¥
    (out_dir / "xgt_var_vocab.json").write_text(
        json.dumps(var_map, indent=2, ensure_ascii=False),
        encoding="utf-8",
    )
    print("âœ… FIT ì™„ë£Œ")
    print(f"- xgt_var_vocab.json ì €ì¥: {out_dir/'xgt_var_vocab.json'}")

    # -----------------------------
    # 1) ì •ê·œí™” íŒŒë¼ë¯¸í„° ê³„ì‚° (Min/Max)
    # -----------------------------
    norm_params: Dict[str, Dict[str, float]] = {
        f: {"min": None, "max": None} for f in NORM_FIELDS
    }

    for feat in rows_raw:
        for f in NORM_FIELDS:
            v = float(feat.get(f, 0.0))
            if norm_params[f]["min"] is None or v < norm_params[f]["min"]:
                norm_params[f]["min"] = v
            if norm_params[f]["max"] is None or v > norm_params[f]["max"]:
                norm_params[f]["max"] = v

    # ë¹ˆ ê²½ìš° ë°©ì–´ì½”ë“œ
    for f in NORM_FIELDS:
        if norm_params[f]["min"] is None:
            norm_params[f]["min"] = 0.0
            norm_params[f]["max"] = 1.0

    # JSON ì €ì¥
    (out_dir / NORM_PARAMS_FILE).write_text(
        json.dumps(norm_params, indent=2, ensure_ascii=False),
        encoding="utf-8",
    )
    print(f"- {NORM_PARAMS_FILE} ì €ì¥: {out_dir / NORM_PARAMS_FILE}")

    # -----------------------------
    # 2) numpy êµ¬ì¡°í™” ë°°ì—´ ìƒì„± (ì •ê·œí™” ì ìš©)
    # -----------------------------    
    dtype = np.dtype([
        ("xgt_var_id", "i4"),   # Embeddingìš© ID (int32)
        ("xgt_var_cnt", "f4"),
        ("xgt_source", "f4"),
        ("xgt_fenet_base", "f4"),
        ("xgt_fenet_slot", "f4"),
        ("xgt_cmd", "f4"),
        ("xgt_dtype", "f4"),
        ("xgt_blkcnt", "f4"),
        ("xgt_err_flag", "f4"),
        ("xgt_err_code", "f4"),
        ("xgt_datasize", "f4"),
        # ğŸ‘‡ ì—¬ê¸° ì¶”ê°€
        ("xgt_addr_count", "f4"),
        ("xgt_addr_min", "f4"),
        ("xgt_addr_max", "f4"),
        ("xgt_addr_range", "f4"),
        ("xgt_word_min", "f4"),
        ("xgt_word_max", "f4"),
        ("xgt_word_mean", "f4"),
        ("xgt_word_std", "f4"),
        # ê¸°ì¡´
        ("xgt_data_missing", "f4"),
        ("xgt_data_len_chars", "f4"),
        ("xgt_data_num_spaces", "f4"),
        ("xgt_data_is_hex", "f4"),
        ("xgt_data_n_bytes", "f4"),
        ("xgt_data_zero_ratio", "f4"),
        ("xgt_data_first_byte", "f4"),
        ("xgt_data_last_byte", "f4"),
        ("xgt_data_mean_byte", "f4"),
        ("xgt_data_bucket", "f4"),
    ])



    data = np.zeros(len(rows_raw), dtype=dtype)

    for idx, raw_feat in enumerate(rows_raw):
        norm_feat = apply_norm_to_xgt_feat(raw_feat, norm_params)
        for name in data.dtype.names:
            data[name][idx] = norm_feat.get(name, 0.0)

    np.save(out_dir / "xgt_fen.npy", data)

    print(f"- xgt_fen.npy ì €ì¥: {out_dir/'xgt_fen.npy'}")
    print(f"- shape: {data.shape}")

    # ì• 5ê°œ ìƒ˜í”Œ ì¶œë ¥
    print("\n===== ì• 5ê°œ xgt_fen ì „ì²˜ë¦¬ ìƒ˜í”Œ (ì •ê·œí™” ì ìš© í›„) =====")
    for i in range(min(5, len(data))):
        sample = {name: data[name][i] for name in data.dtype.names}
        print(sample)


# ---------------------------------------------
# TRANSFORM
# ---------------------------------------------
def transform_preprocess(input_path: Path, out_dir: Path):

    vocab_path = out_dir / "xgt_var_vocab.json"
    if not vocab_path.exists():
        raise FileNotFoundError(f"âŒ {vocab_path} ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € --fit ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

    norm_path = out_dir / NORM_PARAMS_FILE
    if not norm_path.exists():
        raise FileNotFoundError(f"âŒ {norm_path} ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € --fit ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

    var_map = json.loads(vocab_path.read_text(encoding="utf-8"))
    norm_params = json.loads(norm_path.read_text(encoding="utf-8"))

    get_var_id = get_var_id_factory(var_map)

    rows_norm: List[Dict[str, float]] = []

    with input_path.open("r", encoding="utf-8") as fin:
        for line in fin:
            line = line.strip()
            if not line:
                continue
            try:
                obj = json.loads(line)
            except Exception:
                continue

            if obj.get("protocol") != "xgt_fen":
                continue

            raw_feat = preprocess_xgt_record(obj, get_var_id)
            norm_feat = apply_norm_to_xgt_feat(raw_feat, norm_params)
            rows_norm.append(norm_feat)

    dtype = np.dtype([
        ("xgt_var_id", "i4"),
        ("xgt_var_cnt", "f4"),
        ("xgt_source", "f4"),
        ("xgt_fenet_base", "f4"),
        ("xgt_fenet_slot", "f4"),
        ("xgt_cmd", "f4"),
        ("xgt_dtype", "f4"),
        ("xgt_blkcnt", "f4"),
        ("xgt_err_flag", "f4"),
        ("xgt_err_code", "f4"),
        ("xgt_datasize", "f4"),
        ("xgt_addr_count", "f4"),
        ("xgt_addr_min", "f4"),
        ("xgt_addr_max", "f4"),
        ("xgt_addr_range", "f4"),
        ("xgt_word_min", "f4"),
        ("xgt_word_max", "f4"),
        ("xgt_word_mean", "f4"),
        ("xgt_word_std", "f4"),
        ("xgt_data_missing", "f4"),
        ("xgt_data_len_chars", "f4"),
        ("xgt_data_num_spaces", "f4"),
        ("xgt_data_is_hex", "f4"),
        ("xgt_data_n_bytes", "f4"),
        ("xgt_data_zero_ratio", "f4"),
        ("xgt_data_first_byte", "f4"),
        ("xgt_data_last_byte", "f4"),
        ("xgt_data_mean_byte", "f4"),
        ("xgt_data_bucket", "f4"),
    ])


    data = np.zeros(len(rows_norm), dtype=dtype)

    for idx, feat in enumerate(rows_norm):
        for name in data.dtype.names:
            data[name][idx] = feat.get(name, 0.0)

    np.save(out_dir / "xgt_fen.npy", data)

    print("âœ… TRANSFORM ì™„ë£Œ")
    print(f"- xgt_fen.npy ì €ì¥: {out_dir/'xgt_fen.npy'} shape={data.shape}")


# ---------------------------------------------
# MAIN
# ---------------------------------------------
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("-i", "--input", required=True)
    parser.add_argument("-o", "--output", required=True)
    parser.add_argument("--fit", action="store_true")
    parser.add_argument("--transform", action="store_true")

    args = parser.parse_args()
    input_path = Path(args.input)
    out_dir = Path(args.output)

    if args.fit and args.transform:
        raise ValueError("âŒ --fit ê³¼ --transform ëŠ” ë™ì‹œì— ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    if not args.fit and not args.transform:
        raise ValueError("âŒ ë°˜ë“œì‹œ --fit ë˜ëŠ” --transform ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.")

    if args.fit:
        fit_preprocess(input_path, out_dir)
    else:
        transform_preprocess(input_path, out_dir)


"""
ìµœì¢… ë°ì´í„° ì‚¬ìš© (xgt_fen.npy)

    import numpy as np

    data = np.load("output_xgt_fen/xgt_fen.npy")

    # 1) vars embedding ìš© ID (ì´ë¯¸ int32)
    xgt_var_id = data["xgt_var_id"].astype("int32")

    # 2) numeric feature (ì´ë¯¸ ì´ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì •ê·œí™” ì™„ë£Œëœ ê°’ë“¤)
    xgt_numeric = np.stack([
        data["xgt_var_cnt"],        # 0~1
        data["xgt_source"],         # 0~1
        data["xgt_fenet_base"],     # 0~1
        data["xgt_fenet_slot"],     # 0~1
        data["xgt_cmd"],            # 0~1
        data["xgt_dtype"],          # 0~1
        data["xgt_blkcnt"],         # 0~1
        data["xgt_err_flag"],       # 0 or 1
        data["xgt_err_code"],       # 0~1
        data["xgt_datasize"],       # 0~1
        data["xgt_data_missing"],   # 0 or 1
        data["xgt_data_len_chars"], # 0~1
        data["xgt_data_num_spaces"],# 0~1
        data["xgt_data_is_hex"],    # 0 or 1
        data["xgt_data_n_bytes"],   # 0~1
        data["xgt_data_zero_ratio"],# 0~1
        data["xgt_data_first_byte"],# 0~1 (0~255 â†’ /255)
        data["xgt_data_last_byte"], # 0~1
        data["xgt_data_mean_byte"], # 0~1
        data["xgt_data_bucket"],    # hash bucket (ì •ê·œí™” X, í•„ìš”í•˜ë©´ ë³„ë„ embedding ì‚¬ìš©)
    ], axis=1).astype("float32")


ì‹¤ì‹œê°„ ë‹¨ì¼ íŒ¨í‚· ì˜ˆì‹œ:

    import json
    from pathlib import Path
    from preprocess_xgt_fen_embed import preprocess_xgt_fen_with_norm

    out_dir = Path("../result/output_xgt_fen")
    var_map = json.loads((out_dir / "xgt_var_vocab.json").read_text(encoding="utf-8"))
    norm_params = json.loads((out_dir / "xgt_fen_norm_params.json").read_text(encoding="utf-8"))

    pkt = {
        "protocol": "xgt_fen",
        "xgt_fen.source": "0x33",
        "xgt_fen.fenetpos": "0x00",
        "xgt_fen.cmd": "0x0054",
        "xgt_fen.dtype": "0x0014",
        "xgt_fen.blkcnt": "1",
        "xgt_fen.errstat": "0x0000",
        "xgt_fen.vars": "%DB001046",
        "xgt_fen.datasize": "12",
        "xgt_fen.data": "05001e00f50000001c002700",
    }

    feat = preprocess_xgt_fen_with_norm(pkt, var_map, norm_params)
    # feat dictë¥¼ ê·¸ëŒ€ë¡œ ëª¨ë¸ ì…ë ¥ìš© ë²¡í„°ë¡œ ë³€í™˜í•´ì„œ ì‚¬ìš© ê°€ëŠ¥

usage:
    # í•™ìŠµ ë°ì´í„° ê¸°ì¤€ vocab + feature ìƒì„±
    python preprocess_xgt_fen_embed.py --fit -i "../data/ML_DL í•™ìŠµ.jsonl" -o "../result/output_xgt_fen"

    # ìƒˆ ë°ì´í„°(í…ŒìŠ¤íŠ¸/ìš´ì˜) ì „ì²˜ë¦¬
    python preprocess_xgt_fen_embed.py --transform -i "../data/ML_DL í•™ìŠµ.jsonl" -o "../result/output_xgt_fen"
"""
