"""
build_pattern_centroids.py
---------------------------------
SLM ë¼ë²¨ë§ëœ JSONLì—ì„œ íŒ¨í„´ë³„ Latent Vector í‰ê·  ì¶”ì¶œ
LSTM AE Encoder ê¸°ë°˜ centroid ì €ì¥
"""

import json
import numpy as np
import tensorflow as tf
from pathlib import Path
from tqdm import tqdm
from loguru import logger

# ------------------------------------------------------------
# 1ï¸âƒ£ ê¸°ì¡´ Feature Extractor ë¶ˆëŸ¬ì˜¤ê¸°
# ------------------------------------------------------------
from detect_lstm_ae_from_jsonl import extract_features, pad_with_mask

# ------------------------------------------------------------
# 2ï¸âƒ£ ì„¤ì •
# ------------------------------------------------------------
MODEL_PATH = "outputs/models/LSTM_AE_Flexible_v2.keras"
JSONL_PATH = "dataset/PLS-JSONL/final.jsonl"
OUTPUT_PATH = "outputs/pattern_centroids.npy"

# ------------------------------------------------------------
# 3ï¸âƒ£ ëª¨ë¸ ë¡œë“œ ë° Encoder ì¶”ì¶œ
# ------------------------------------------------------------
logger.info(f"ğŸš€ Loading LSTM Autoencoder: {MODEL_PATH}")
model = tf.keras.models.load_model(MODEL_PATH)
encoder = tf.keras.Model(inputs=model.input, outputs=model.get_layer("lstm_1").output)


def pad_with_fixed_length(X_list, fixed_len=14):
    """ëª¨ë¸ ì…ë ¥ ê¸¸ì´ì— ë§ê²Œ ê°•ì œë¡œ íŒ¨ë”©"""
    feat_dim = X_list[0].shape[1]
    X_padded = np.zeros((len(X_list), fixed_len, feat_dim), dtype="float32")
    for i, x in enumerate(X_list):
        length = min(x.shape[0], fixed_len)
        X_padded[i, :length, :] = x[:length]
    return X_padded


# ------------------------------------------------------------
# 4ï¸âƒ£ JSONL ë¡œë“œ
# ------------------------------------------------------------
def load_labeled_sequences(path):
    data_by_label = {}
    with open(path, "r", encoding="utf-8") as f:
        for line in tqdm(f, desc="ğŸ“¥ Loading labeled SLM windows"):
            try:
                obj = json.loads(line)
                label = obj.get("label")
                seq = obj.get("window_group")
                if not label or not seq:
                    continue
                feats = [extract_features(pkt) for pkt in seq]
                if len(feats) < 2:
                    continue
                data_by_label.setdefault(label, []).append(np.array(feats, dtype="float32"))
            except Exception as e:
                logger.warning(f"âš ï¸ JSON decode error: {e}")
    logger.info(f"âœ… Loaded {sum(len(v) for v in data_by_label.values())} windows across {len(data_by_label)} labels")
    return data_by_label

# ------------------------------------------------------------
# 5ï¸âƒ£ íŒ¨í„´ë³„ Latent í‰ê·  ê³„ì‚°
# ------------------------------------------------------------
def compute_pattern_centroids(data_by_label):
    centroids = {}
    for label, seqs in data_by_label.items():
        # X_padded = pad_with_mask(seqs)
        X_padded = pad_with_fixed_length(seqs, fixed_len=14)
        latent = encoder.predict(X_padded, verbose=0)
        centroids[label] = np.mean(latent, axis=0)
        logger.info(f"ğŸ“Š {label}: {len(seqs)} seqs â†’ centroid shape={centroids[label].shape}")
    return centroids

# ------------------------------------------------------------
# 6ï¸âƒ£ ì €ì¥
# ------------------------------------------------------------
if __name__ == "__main__":
    data_by_label = load_labeled_sequences(JSONL_PATH)
    centroids = compute_pattern_centroids(data_by_label)
    np.save(OUTPUT_PATH, centroids)
    logger.success(f"ğŸ’¾ Saved pattern centroids â†’ {OUTPUT_PATH}")
